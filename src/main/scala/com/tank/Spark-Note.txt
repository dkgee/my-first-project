


学习参考地址1：http://www.cnblogs.com/shishanyuan/p/4699644.html
学习参考地址2：http://doc.mbalib.com/view/ee1bd736e4f6898317237aa0aecf289f.html

Spark知识部分
    基础篇
        1，诞生背景、演进历程
        2，生态圈组成
        3，环境搭建
    核心篇
        1，编程模型
        2，核心原理
            通信机制、作业执行原理、调度算法、容错、监控管理
        3，存储原理
        4，运行架构
    组件篇
        1，Spark SQL即席查询
        2，Spark Streaming实时流处理应用
        3，MLbase/MLlib的机器学习
        4，GraphX的图处理

        5，SparkR的数据计算
        6，Alluxio的分布式内存文件系统


1,Spark底层核心
    架构信息
        物理节点信息
            Cluster Manager(Master)、Worker Node(Worker)
        软件应用信息
            Driver Program、Executor、Task
    性能特点
        并行内存计算
        速度快
        通用性强
        容错性
    RDD
    函数库
    缓存
    DAG(有向无环图)

    Spark运行模式(5种)
        运行环境                  模式                      描述
        Local                   本地模式            常用于本地开发测试，本地还分为local单线程和local-cluster多线程
        Standalone              集群模式            典型的Master/Slave模式;Spark支持Zookeeper来实现HA
        On yarn                 集群模式            运行在yarn资源管理器框架上，由yarn负责资源管理，Spark负责任务调度和计算
        On mesos                集群模式            运行在mesos资源管理器框架上，有mesos负责资源管理，Spark负责任务调度和计算
        On cloud                集群模式            运行在云服务资源管理框架上，比如AWS的EC2,能够很方便访问Amazon的S3;Spark支持多种分布式存储系统：HDFS和S3
    常用术语
            术语                 描述
        Application             Spark应用程序，包含一个Driver Program和若干个Executor
        SparkContext            Spark应用程序入口，负责调度各个运算资源，协调各个Worker Node上的Executor
        Driver Program          运行Application的main函数，并且创建SparkContext
        Executor                是指Application运行在Worker Node上的一个进程，该进程负责运行Task，并且负责将数据存在内存或磁盘上。每个Application都会申请各自的Executor来处理任务。
        Cluster Manager         在集群上获取资源的外部服务(例如：Standalone、Mesos、Yarn)
        Worker Node             集群上任何可以运行Application代码的节点，运行一个或多个Executor进程
        Task                    运行在Executor上的工作单元
        Job                     SparkContext提交的具体Action操作，常和Action对应
        Stage                   每个Job会被拆分成很多task,每组任务被称为Stage,也称TaskSet
        RDD                     是Resilient Distributed Datasets的简称，中文为弹性分布式数据集;是Spark最核心的模块和类
        DAGScheduler            根据Job构建基于Stage的DAG,并提交Stage给TaskScheduler
        TaskScheduler           将Taskset提交给Worker Node集群运行并返回结果
        Transformations         是Spark API的一种类型，Transformation返回值还是一个RDD,所有的Transformation采用的都是懒策略，如果只是将Transformation提交是不会执行计算的
        Action                  是Spark API的一种类型，Action返回值不是一个RDD，而是一个scala集合;计算只有在Action被提交的时候计算才被触发

Spark Core
    DAG             计算框架
    RDD             分布式数据集
    Partition       数据分块
    ThreadPools     多线程池
    Akka            通讯框架






